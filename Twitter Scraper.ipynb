{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import time\n",
    "import datetime\n",
    "import requests\n",
    "import bs4\n",
    "import selenium\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# os.chdir(r'C:\\Users\\Ben\\Documents\\2019 Summer\\TradingAlgo\\Tweets')\n",
    "# os.mkdir(r'C:\\Users\\Ben\\Documents\\2019 Summer\\TradingAlgo\\Tweets\\bitcoin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_Key = 'ILYTd5Abkw85OKTd5sAbSpPdC'\n",
    "C_Secret='1hHTjqyq5Kitt3b5gka6uPMkvKzuz5wO7C63HcRLP5v2mHUtz6'\n",
    "A_Token='2758135350-UfWPEgJPQJTCHvCQRQEzcavyl45mcwwLkRnWWBi'\n",
    "A_Token_Secret='LKa0IlzGhWdLKgzhATUtFx0kM5AGG6lAWBUoOEP1lKj9g'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key=C_Key, consumer_secret=C_Secret)\n",
    "auth.set_access_token(A_Token, A_Token_Secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chrome_option = Options()\n",
    "chrome_option.add_argument(r'user-data-dir=C:\\Users\\Ben\\AppData\\Local\\Google\\Chrome\\User Data\\Default')\n",
    "chrome_option.add_argument(\"--no-sandbox\")\n",
    "chrome_option.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_option.add_argument(\"--headless\")\n",
    "chrome_option.add_experimental_option('w3c', False)\n",
    "browser = webdriver.Chrome(executable_path=r'C:\\Users\\Ben\\Documents\\Varsity Surf\\chromedriver_win32\\chromedriver.exe',chrome_options=chrome_option)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Tweet_Collecter(object):\n",
    "    \n",
    "    def __init__(self, init_browser=True, browser=None):\n",
    "        \n",
    "        import os\n",
    "        import math\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from selenium.webdriver.chrome.options import Options\n",
    "        from selenium import webdriver\n",
    "        import tweepy\n",
    "        import time\n",
    "        import datetime\n",
    "        import requests\n",
    "        \n",
    "        self.init_browser= init_browser\n",
    "        \n",
    "        self.C_Key = 'ILYTd5Abkw85OKTd5sAbSpPdC'\n",
    "        self.C_Secret='1hHTjqyq5Kitt3b5gka6uPMkvKzuz5wO7C63HcRLP5v2mHUtz6'\n",
    "        self.A_Token='2758135350-UfWPEgJPQJTCHvCQRQEzcavyl45mcwwLkRnWWBi'\n",
    "        self.A_Token_Secret='LKa0IlzGhWdLKgzhATUtFx0kM5AGG6lAWBUoOEP1lKj9g'\n",
    "\n",
    "        auth = tweepy.OAuthHandler(consumer_key=C_Key, consumer_secret=C_Secret)\n",
    "        auth.set_access_token(A_Token, A_Token_Secret)\n",
    "        self.auth = auth\n",
    "        \n",
    "        self.api = tweepy.API(auth)\n",
    "        if init_browser:\n",
    "            chrome_option = Options()\n",
    "            chrome_option.add_argument(r'user-data-dir=C:\\Users\\Ben\\AppData\\Local\\Google\\Chrome\\User Data\\Default')\n",
    "            chrome_option.add_argument(\"--no-sandbox\")\n",
    "            chrome_option.add_argument(\"--disable-dev-shm-usage\")\n",
    "            chrome_option.add_argument(\"--headless\")\n",
    "            self.browser = webdriver.Chrome(executable_path=r'C:\\Users\\Ben\\Documents\\Varsity Surf\\chromedriver_win32\\chromedriver.exe',\n",
    "                                            chrome_options=chrome_option)\n",
    "        else:\n",
    "            self.browser = browser\n",
    "    \n",
    "    def collect_tweets(self, filters = ['#btc', 'bitcoin'], start_date=datetime.datetime.today()-datetime.timedelta(days=1),\n",
    "                       end_date= datetime.datetime.today(), approx_tweets_per_interval = 200, interval_mins=20,\n",
    "                      save_folder_name='temp', filename='bitcoin', round_interval = True):\n",
    "    \n",
    "        browser = self.browser\n",
    "        api = self.api\n",
    "        \n",
    "        if round_interval:\n",
    "            start_date = start_date - datetime.timedelta(minutes=start_date.minute % interval_mins,\n",
    "                                 seconds= start_date.second,\n",
    "                                 microseconds=start_date.microsecond)\n",
    "\n",
    "        if start_date>end_date:\n",
    "            raise Exception('Start date must be after end date')\n",
    "\n",
    "        print('Calculating tweet ids to be collected...')\n",
    "        ################### Find id of tweet exactly 24 hours later\n",
    "        since_datetime = start_date.date()\n",
    "        since_datetime = datetime.datetime(since_datetime.year, since_datetime.month, since_datetime.day)\n",
    "        until_datetime = (start_date + datetime.timedelta(days=1)).date()\n",
    "        until_datetime = datetime.datetime(until_datetime.year, until_datetime.month, until_datetime.day)\n",
    "        end_datetime = end_date.date()\n",
    "        end_datetime = datetime.datetime(end_datetime.year, end_datetime.month, end_datetime.day)\n",
    "\n",
    "        since_date = since_datetime.isoformat()[:10]\n",
    "        until_date = until_datetime.isoformat()[:10]\n",
    "\n",
    "\n",
    "        filters = [fil.replace('#','%23') for fil in filters]\n",
    "        self.filters = filters\n",
    "        query_filters = str('%20OR%20'.join(filters))\n",
    "        query = query_filters + '%20since%3A'+since_date+'%20until%3A'+until_date+'&src=typd'\n",
    "\n",
    "        base_url = 'https://twitter.com/search?f=tweets&q='\n",
    "        url = base_url + query\n",
    "        browser.get(url) \n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "        endtweet_id = int(browser.find_elements_by_class_name('js-actionable-tweet')[0].get_attribute('data-tweet-id'))\n",
    "\n",
    "        #################### Find id of last tweet before timeperiod starts\n",
    "\n",
    "        until_datetime2 = start_date.date()\n",
    "        until_datetime2 = datetime.datetime(until_datetime2.year, until_datetime2.month, until_datetime2.day)\n",
    "        until_date2 = until_datetime2.isoformat()[:10]\n",
    "\n",
    "        query = query_filters + '%20until%3A'+until_date2+'%20lang%3Aen&src=typd'\n",
    "\n",
    "        url = base_url + query\n",
    "\n",
    "        browser.get(url) \n",
    "        time.sleep(1)\n",
    "\n",
    "        starttweet_id = int(browser.find_elements_by_class_name('js-actionable-tweet')[0].get_attribute('data-tweet-id'))\n",
    "\n",
    "        #################### calculate tweet id pairs needed to collect correct tweets at each sub-timeperiod\n",
    "\n",
    "\n",
    "        id_interval = (endtweet_id - starttweet_id)/((60*24)/interval_mins)\n",
    "\n",
    "        ##calculate which id to start on and end on\n",
    "        ##start tweet\n",
    "        start_timejump = start_date - since_datetime #difference between time specified to start at and time at which\n",
    "                                               #starttweet_id currently specifies to collect from\n",
    "        start_intervalsjump = int(math.ceil(start_timejump.total_seconds()/(60*interval_mins)))\n",
    "\n",
    "\n",
    "        total_timeperiod_length = end_date - start_date #total length of time over whole specified timeperiod\n",
    "                                                        # enables calculation of how many id intervals need to be collected\n",
    "\n",
    "        num_intervals= math.ceil(total_timeperiod_length.total_seconds()/(60*interval_mins)) #number of intervals to collect\n",
    "\n",
    "        start_id = int(starttweet_id + start_intervalsjump * id_interval)\n",
    "\n",
    "        since_ids= [int(start_id + i*id_interval) for i in range(num_intervals)]\n",
    "        max_ids = [int(x + id_interval) for x in since_ids]\n",
    "        \n",
    "        time_range = pd.date_range(start = start_date, end = end_date, freq = str(interval_mins)+'min')\n",
    "\n",
    "        print('Tweet ids calculated!')\n",
    "\n",
    "        ################## Start tweet collection\n",
    "        \n",
    "        ## initialise class for scrolling webpage\n",
    "        class wait_for_more_than_n_elements_to_be_present(object):\n",
    "                def __init__(self, locator, count):\n",
    "                    self.locator = locator\n",
    "                    self.count = count\n",
    "\n",
    "                def __call__(self, browser):\n",
    "                    try:\n",
    "                        elements = EC._find_elements(browser, self.locator)\n",
    "                        return len(elements) > self.count\n",
    "                    except StaleElementReferenceException:\n",
    "                        return False\n",
    "        \n",
    "        \n",
    "        filepath_stem = r'C:\\Users\\Ben\\Documents\\2019 Summer\\TradingAlgo\\Tweets\\ '.strip() + save_folder_name + r'\\ '.strip()       \n",
    "        if not os.path.exists(filepath_stem):\n",
    "            os.mkdir(filepath_stem)\n",
    "    \n",
    "        print('Beginning tweet collection:')\n",
    "        iteration_counter=1\n",
    "\n",
    "        for since_id, max_id, timestamp in zip(since_ids,max_ids, time_range): # for each subtimeperiod/interval of tweets\n",
    "\n",
    "            print('Collecting tweets from interval:',iteration_counter)\n",
    "            iteration_counter+=1\n",
    "\n",
    "            query = query_filters + '%20since_id%3A'+str(int(since_id))+'%20max_id%3A'+str(int(max_id))+'&src=typd'\n",
    "            url = base_url + query\n",
    "\n",
    "                    \n",
    "            browser.get(url)\n",
    "            \n",
    "            wait = WebDriverWait(browser, 10)\n",
    "            try:\n",
    "                # wait until the first search result is found. Search results will be tweets, which are html list items and have the class='data-item-id':\n",
    "                wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"li[data-item-id]\")))\n",
    "\n",
    "                # scroll down to the last tweet until there are no more tweets:\n",
    "                number_of_tweets=0\n",
    "                while number_of_tweets<approx_tweets_per_interval:\n",
    "\n",
    "                    # extract all the tweets:\n",
    "                    tweets = browser.find_elements_by_css_selector(\"li[data-item-id]\")\n",
    "\n",
    "                    # find number of visible tweets:\n",
    "                    number_of_tweets = len(tweets)\n",
    "\n",
    "                    # keep scrolling:\n",
    "                    browser.execute_script(\"arguments[0].scrollIntoView();\", tweets[-1])\n",
    "\n",
    "                    try:\n",
    "                        # wait for more tweets to be visible:\n",
    "                        wait.until(wait_for_more_than_n_elements_to_be_present(\n",
    "                            (By.CSS_SELECTOR, \"li[data-item-id]\"), number_of_tweets))\n",
    "                    \n",
    "                    except TimeoutException:\n",
    "                        # if no more are visible the \"wait.until\" call will timeout. Catch the exception and exit the while loop:\n",
    "                        print(number_of_tweets)\n",
    "                        break\n",
    "\n",
    "                # extract the html for the whole lot:\n",
    "                page_source = browser.page_source\n",
    "\n",
    "            except TimeoutException:\n",
    "                print('Likely issue: No tweets from query')\n",
    "                \n",
    "            # Extract data from webpage\n",
    "            soup = bs4.BeautifulSoup(page_source)\n",
    "\n",
    "            tweets = []\n",
    "            for li in soup.find_all(\"li\", class_='js-stream-item'):\n",
    "\n",
    "                # If our li doesn't have a tweet-id, we skip it as it's not going to be a tweet.\n",
    "                if 'data-item-id' not in li.attrs:\n",
    "                    continue\n",
    "\n",
    "                else:\n",
    "                    tweet = {\n",
    "                        'tweet_id': li['data-item-id'],\n",
    "                        'text': None,\n",
    "                        'user_id': None,\n",
    "                        'user_screen_name': None,\n",
    "                        'user_name': None,\n",
    "                        'created_at': None,\n",
    "                        'retweets': 0,\n",
    "                        'likes': 0,\n",
    "                        'replies': 0\n",
    "                    }\n",
    "\n",
    "                # Tweet Text\n",
    "                text_p = li.find(\"p\", class_=\"tweet-text\")\n",
    "                if text_p is not None:\n",
    "                    tweet['text'] = text_p.get_text()\n",
    "\n",
    "                # Tweet User ID, User Screen Name, User Name\n",
    "                user_details_div = li.find(\"div\", class_=\"tweet\")\n",
    "                if user_details_div is not None:\n",
    "                    tweet['user_id'] = user_details_div['data-user-id']\n",
    "                    tweet['user_screen_name'] = user_details_div['data-screen-name']\n",
    "                    tweet['user_name'] = user_details_div['data-name']\n",
    "\n",
    "                # Tweet date\n",
    "                date_span = li.find(\"span\", class_=\"_timestamp\")\n",
    "                if date_span is not None:\n",
    "                    tweet['created_at'] = float(date_span['data-time-ms'])\n",
    "\n",
    "                # Tweet Retweets\n",
    "                retweet_span = li.select(\"span.ProfileTweet-action--retweet > span.ProfileTweet-actionCount\")\n",
    "                if retweet_span is not None and len(retweet_span) > 0:\n",
    "                        tweet['retweets'] = int(retweet_span[0]['data-tweet-stat-count'])\n",
    "\n",
    "                # Tweet Likes\n",
    "                like_span = li.select(\"span.ProfileTweet-action--favorite > span.ProfileTweet-actionCount\")\n",
    "                if like_span is not None and len(like_span) > 0:\n",
    "                    tweet['likes'] = int(like_span[0]['data-tweet-stat-count'])\n",
    "\n",
    "                # Tweet Replies\n",
    "                reply_span = li.select(\"span.ProfileTweet-action--reply > span.ProfileTweet-actionCount\")\n",
    "                if reply_span is not None and len(reply_span) > 0:\n",
    "                    tweet['replies'] = int(reply_span[0]['data-tweet-stat-count'])\n",
    "\n",
    "                tweets.append(tweet)\n",
    "\n",
    "            ### convert data to dataframe\n",
    "\n",
    "            tweets_df= pd.DataFrame(data=tweets)\n",
    "\n",
    "            #tweets_df['followers'] = tweets_df['user_id'].apply(lambda x: api.get_user(x)._json['followers_count'])\n",
    "            savefile = filepath_stem + filename + timestamp.isoformat()[:19].replace(':','') +'.csv'\n",
    "\n",
    "            tweets_df.to_csv(savefile)\n",
    "\n",
    "        print('Finished!')\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating tweet ids to be collected...\n",
      "Tweet ids calculated!\n",
      "Beginning tweet collection:\n",
      "Collecting tweets from interval: 1\n",
      "140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\Ben\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweets from interval: 2\n",
      "1093\n",
      "Collecting tweets from interval: 3\n",
      "1087\n",
      "Collecting tweets from interval: 4\n",
      "892\n",
      "Collecting tweets from interval: 5\n",
      "962\n",
      "Collecting tweets from interval: 6\n",
      "835\n",
      "Collecting tweets from interval: 7\n",
      "891\n",
      "Collecting tweets from interval: 8\n",
      "832\n",
      "Collecting tweets from interval: 9\n",
      "1047\n",
      "Collecting tweets from interval: 10\n",
      "1011\n",
      "Collecting tweets from interval: 11\n",
      "1151\n",
      "Collecting tweets from interval: 12\n",
      "1067\n",
      "Collecting tweets from interval: 13\n",
      "1231\n",
      "Collecting tweets from interval: 14\n",
      "1237\n",
      "Collecting tweets from interval: 15\n",
      "1302\n",
      "Collecting tweets from interval: 16\n",
      "1305\n",
      "Collecting tweets from interval: 17\n",
      "1358\n",
      "Collecting tweets from interval: 18\n",
      "1261\n",
      "Collecting tweets from interval: 19\n",
      "1276\n",
      "Collecting tweets from interval: 20\n",
      "1166\n",
      "Collecting tweets from interval: 21\n",
      "1163\n",
      "Collecting tweets from interval: 22\n",
      "1170\n",
      "Collecting tweets from interval: 23\n",
      "1049\n",
      "Collecting tweets from interval: 24\n",
      "1003\n",
      "Collecting tweets from interval: 25\n",
      "931\n",
      "Collecting tweets from interval: 26\n",
      "866\n",
      "Collecting tweets from interval: 27\n",
      "868\n",
      "Collecting tweets from interval: 28\n",
      "847\n",
      "Collecting tweets from interval: 29\n",
      "821\n",
      "Collecting tweets from interval: 30\n",
      "767\n",
      "Collecting tweets from interval: 31\n",
      "760\n",
      "Collecting tweets from interval: 32\n",
      "945\n",
      "Collecting tweets from interval: 33\n",
      "962\n",
      "Collecting tweets from interval: 34\n",
      "996\n",
      "Collecting tweets from interval: 35\n",
      "1035\n",
      "Collecting tweets from interval: 36\n",
      "1029\n",
      "Collecting tweets from interval: 37\n",
      "1268\n",
      "Collecting tweets from interval: 38\n",
      "1358\n",
      "Collecting tweets from interval: 39\n",
      "1275\n",
      "Collecting tweets from interval: 40\n",
      "1179\n",
      "Collecting tweets from interval: 41\n",
      "1160\n",
      "Collecting tweets from interval: 42\n",
      "1167\n",
      "Collecting tweets from interval: 43\n",
      "1176\n",
      "Collecting tweets from interval: 44\n",
      "236\n",
      "Collecting tweets from interval: 45\n",
      "1060\n",
      "Collecting tweets from interval: 46\n",
      "1026\n",
      "Collecting tweets from interval: 47\n",
      "1074\n",
      "Collecting tweets from interval: 48\n",
      "331\n",
      "Collecting tweets from interval: 49\n",
      "957\n",
      "Collecting tweets from interval: 50\n",
      "898\n",
      "Collecting tweets from interval: 51\n",
      "863\n",
      "Collecting tweets from interval: 52\n",
      "968\n",
      "Collecting tweets from interval: 53\n",
      "170\n",
      "Collecting tweets from interval: 54\n",
      "1155\n",
      "Collecting tweets from interval: 55\n",
      "1150\n",
      "Collecting tweets from interval: 56\n",
      "1136\n",
      "Collecting tweets from interval: 57\n",
      "1144\n",
      "Collecting tweets from interval: 58\n",
      "1246\n",
      "Collecting tweets from interval: 59\n",
      "1249\n",
      "Collecting tweets from interval: 60\n",
      "1338\n",
      "Collecting tweets from interval: 61\n",
      "523\n",
      "Collecting tweets from interval: 62\n",
      "1557\n",
      "Collecting tweets from interval: 63\n",
      "1452\n",
      "Collecting tweets from interval: 64\n",
      "498\n",
      "Collecting tweets from interval: 65\n",
      "1536\n",
      "Collecting tweets from interval: 66\n",
      "199\n",
      "Collecting tweets from interval: 67\n",
      "1446\n",
      "Collecting tweets from interval: 68\n",
      "1350\n",
      "Collecting tweets from interval: 69\n",
      "1376\n",
      "Collecting tweets from interval: 70\n",
      "1129\n",
      "Collecting tweets from interval: 71\n",
      "1179\n",
      "Collecting tweets from interval: 72\n",
      "1225\n",
      "Collecting tweets from interval: 73\n",
      "1664\n",
      "Collecting tweets from interval: 74\n",
      "1097\n",
      "Collecting tweets from interval: 75\n",
      "974\n",
      "Collecting tweets from interval: 76\n",
      "887\n",
      "Collecting tweets from interval: 77\n",
      "1076\n",
      "Collecting tweets from interval: 78\n",
      "1054\n",
      "Collecting tweets from interval: 79\n",
      "1097\n",
      "Collecting tweets from interval: 80\n",
      "1205\n",
      "Collecting tweets from interval: 81\n",
      "1226\n",
      "Collecting tweets from interval: 82\n",
      "1178\n",
      "Collecting tweets from interval: 83\n",
      "794\n",
      "Collecting tweets from interval: 84\n",
      "1216\n",
      "Collecting tweets from interval: 85\n",
      "1454\n",
      "Collecting tweets from interval: 86\n",
      "1303\n",
      "Collecting tweets from interval: 87\n",
      "1393\n",
      "Collecting tweets from interval: 88\n",
      "1430\n",
      "Collecting tweets from interval: 89\n",
      "1424\n",
      "Collecting tweets from interval: 90\n",
      "1614\n",
      "Collecting tweets from interval: 91\n",
      "1562\n",
      "Collecting tweets from interval: 92\n",
      "1422\n",
      "Collecting tweets from interval: 93\n",
      "1389\n",
      "Collecting tweets from interval: 94\n",
      "1230\n",
      "Collecting tweets from interval: 95\n",
      "1204\n",
      "Collecting tweets from interval: 96\n",
      "1101\n",
      "Collecting tweets from interval: 97\n",
      "1054\n",
      "Collecting tweets from interval: 98\n",
      "996\n",
      "Collecting tweets from interval: 99\n",
      "986\n",
      "Collecting tweets from interval: 100\n",
      "851\n",
      "Collecting tweets from interval: 101\n",
      "950\n",
      "Collecting tweets from interval: 102\n",
      "1003\n",
      "Collecting tweets from interval: 103\n",
      "1045\n",
      "Collecting tweets from interval: 104\n",
      "1148\n",
      "Collecting tweets from interval: 105\n",
      "1202\n",
      "Collecting tweets from interval: 106\n",
      "1135\n",
      "Collecting tweets from interval: 107\n",
      "1209\n",
      "Collecting tweets from interval: 108\n",
      "1333\n",
      "Collecting tweets from interval: 109\n",
      "215\n",
      "Collecting tweets from interval: 110\n",
      "1517\n",
      "Collecting tweets from interval: 111\n",
      "1652\n",
      "Collecting tweets from interval: 112\n",
      "1582\n",
      "Collecting tweets from interval: 113\n",
      "1468\n",
      "Collecting tweets from interval: 114\n",
      "1546\n",
      "Collecting tweets from interval: 115\n",
      "1431\n",
      "Collecting tweets from interval: 116\n",
      "1297\n",
      "Collecting tweets from interval: 117\n",
      "1421\n",
      "Collecting tweets from interval: 118\n",
      "1222\n",
      "Collecting tweets from interval: 119\n",
      "1198\n",
      "Collecting tweets from interval: 120\n",
      "1003\n",
      "Collecting tweets from interval: 121\n",
      "943\n",
      "Collecting tweets from interval: 122\n",
      "1002\n",
      "Collecting tweets from interval: 123\n",
      "914\n",
      "Collecting tweets from interval: 124\n",
      "950\n",
      "Collecting tweets from interval: 125\n",
      "949\n",
      "Collecting tweets from interval: 126\n",
      "1047\n",
      "Collecting tweets from interval: 127\n",
      "1087\n",
      "Collecting tweets from interval: 128\n",
      "1178\n",
      "Collecting tweets from interval: 129\n",
      "1085\n",
      "Collecting tweets from interval: 130\n",
      "1055\n",
      "Collecting tweets from interval: 131\n",
      "1207\n",
      "Collecting tweets from interval: 132\n",
      "1309\n",
      "Collecting tweets from interval: 133\n",
      "1323\n",
      "Collecting tweets from interval: 134\n",
      "1501\n",
      "Collecting tweets from interval: 135\n",
      "1504\n",
      "Collecting tweets from interval: 136\n",
      "1416\n",
      "Collecting tweets from interval: 137\n",
      "1452\n",
      "Collecting tweets from interval: 138\n",
      "1395\n",
      "Collecting tweets from interval: 139\n",
      "1497\n",
      "Collecting tweets from interval: 140\n",
      "1330\n",
      "Collecting tweets from interval: 141\n",
      "1240\n",
      "Collecting tweets from interval: 142\n",
      "1153\n",
      "Collecting tweets from interval: 143\n",
      "1035\n",
      "Collecting tweets from interval: 144\n",
      "971\n",
      "Collecting tweets from interval: 145\n",
      "878\n",
      "Collecting tweets from interval: 146\n",
      "939\n",
      "Collecting tweets from interval: 147\n",
      "794\n",
      "Collecting tweets from interval: 148\n",
      "806\n",
      "Collecting tweets from interval: 149\n",
      "874\n",
      "Collecting tweets from interval: 150\n",
      "828\n",
      "Collecting tweets from interval: 151\n",
      "1063\n",
      "Collecting tweets from interval: 152\n",
      "1294\n",
      "Collecting tweets from interval: 153\n",
      "1151\n",
      "Collecting tweets from interval: 154\n",
      "684\n",
      "Collecting tweets from interval: 155\n",
      "1221\n",
      "Collecting tweets from interval: 156\n",
      "1311\n",
      "Collecting tweets from interval: 157\n",
      "1355\n",
      "Collecting tweets from interval: 158\n",
      "1473\n",
      "Collecting tweets from interval: 159\n",
      "1503\n",
      "Collecting tweets from interval: 160\n",
      "1509\n",
      "Collecting tweets from interval: 161\n",
      "1526\n",
      "Collecting tweets from interval: 162\n",
      "1422\n",
      "Collecting tweets from interval: 163\n",
      "568\n",
      "Collecting tweets from interval: 164\n",
      "1466\n",
      "Collecting tweets from interval: 165\n",
      "1343\n",
      "Collecting tweets from interval: 166\n",
      "320\n",
      "Collecting tweets from interval: 167\n",
      "379\n",
      "Collecting tweets from interval: 168\n",
      "1080\n",
      "Collecting tweets from interval: 169\n",
      "886\n",
      "Collecting tweets from interval: 170\n",
      "901\n",
      "Collecting tweets from interval: 171\n",
      "769\n",
      "Collecting tweets from interval: 172\n",
      "694\n",
      "Collecting tweets from interval: 173\n",
      "770\n",
      "Collecting tweets from interval: 174\n",
      "838\n",
      "Collecting tweets from interval: 175\n",
      "783\n",
      "Collecting tweets from interval: 176\n",
      "1075\n",
      "Collecting tweets from interval: 177\n",
      "901\n",
      "Collecting tweets from interval: 178\n",
      "907\n",
      "Collecting tweets from interval: 179\n",
      "1007\n",
      "Collecting tweets from interval: 180\n",
      "967\n",
      "Collecting tweets from interval: 181\n",
      "1034\n",
      "Collecting tweets from interval: 182\n",
      "1088\n",
      "Collecting tweets from interval: 183\n",
      "1139\n",
      "Collecting tweets from interval: 184\n",
      "1109\n",
      "Collecting tweets from interval: 185\n",
      "1064\n",
      "Collecting tweets from interval: 186\n",
      "1090\n",
      "Collecting tweets from interval: 187\n",
      "1052\n",
      "Collecting tweets from interval: 188\n",
      "1052\n",
      "Collecting tweets from interval: 189\n",
      "949\n",
      "Collecting tweets from interval: 190\n",
      "924\n",
      "Collecting tweets from interval: 191\n",
      "857\n",
      "Collecting tweets from interval: 192\n",
      "768\n",
      "Collecting tweets from interval: 193\n",
      "792\n",
      "Collecting tweets from interval: 194\n",
      "742\n",
      "Collecting tweets from interval: 195\n",
      "715\n",
      "Collecting tweets from interval: 196\n",
      "687\n",
      "Collecting tweets from interval: 197\n",
      "735\n",
      "Collecting tweets from interval: 198\n",
      "760\n",
      "Collecting tweets from interval: 199\n",
      "741\n",
      "Collecting tweets from interval: 200\n",
      "869\n",
      "Collecting tweets from interval: 201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814\n",
      "Collecting tweets from interval: 202\n",
      "396\n",
      "Collecting tweets from interval: 203\n",
      "951\n",
      "Collecting tweets from interval: 204\n",
      "900\n",
      "Collecting tweets from interval: 205\n",
      "1041\n",
      "Collecting tweets from interval: 206\n",
      "1134\n",
      "Collecting tweets from interval: 207\n",
      "1152\n",
      "Collecting tweets from interval: 208\n",
      "1086\n",
      "Collecting tweets from interval: 209\n",
      "1182\n",
      "Collecting tweets from interval: 210\n",
      "1046\n",
      "Collecting tweets from interval: 211\n",
      "1121\n",
      "Collecting tweets from interval: 212\n",
      "1090\n",
      "Collecting tweets from interval: 213\n",
      "995\n",
      "Collecting tweets from interval: 214\n",
      "944\n",
      "Collecting tweets from interval: 215\n",
      "930\n",
      "Collecting tweets from interval: 216\n",
      "816\n",
      "Collecting tweets from interval: 217\n",
      "741\n",
      "Collecting tweets from interval: 218\n",
      "894\n",
      "Collecting tweets from interval: 219\n",
      "836\n",
      "Collecting tweets from interval: 220\n",
      "751\n",
      "Collecting tweets from interval: 221\n",
      "749\n",
      "Collecting tweets from interval: 222\n",
      "894\n",
      "Collecting tweets from interval: 223\n",
      "118\n",
      "Collecting tweets from interval: 224\n",
      "1133\n",
      "Collecting tweets from interval: 225\n",
      "1041\n",
      "Collecting tweets from interval: 226\n",
      "1063\n",
      "Collecting tweets from interval: 227\n",
      "476\n",
      "Collecting tweets from interval: 228\n",
      "1467\n",
      "Collecting tweets from interval: 229\n",
      "1566\n",
      "Collecting tweets from interval: 230\n",
      "1538\n",
      "Collecting tweets from interval: 231\n",
      "1566\n",
      "Collecting tweets from interval: 232\n",
      "1464\n",
      "Collecting tweets from interval: 233\n",
      "316\n",
      "Collecting tweets from interval: 234\n",
      "827\n",
      "Collecting tweets from interval: 235\n",
      "1292\n",
      "Collecting tweets from interval: 236\n",
      "1303\n",
      "Collecting tweets from interval: 237\n",
      "1223\n",
      "Collecting tweets from interval: 238\n",
      "1061\n",
      "Collecting tweets from interval: 239\n",
      "1058\n",
      "Collecting tweets from interval: 240\n",
      "1051\n",
      "Collecting tweets from interval: 241\n",
      "1008\n",
      "Collecting tweets from interval: 242\n",
      "926\n",
      "Collecting tweets from interval: 243\n",
      "814\n",
      "Collecting tweets from interval: 244\n",
      "811\n",
      "Collecting tweets from interval: 245\n",
      "906\n",
      "Collecting tweets from interval: 246\n",
      "874\n",
      "Collecting tweets from interval: 247\n",
      "923\n",
      "Collecting tweets from interval: 248\n",
      "1095\n",
      "Collecting tweets from interval: 249\n",
      "1110\n",
      "Collecting tweets from interval: 250\n",
      "1108\n",
      "Collecting tweets from interval: 251\n",
      "1267\n",
      "Collecting tweets from interval: 252\n",
      "1256\n",
      "Collecting tweets from interval: 253\n",
      "180\n",
      "Collecting tweets from interval: 254\n",
      "1342\n",
      "Collecting tweets from interval: 255\n",
      "1457\n",
      "Collecting tweets from interval: 256\n",
      "1368\n",
      "Collecting tweets from interval: 257\n",
      "1385\n",
      "Collecting tweets from interval: 258\n",
      "1373\n",
      "Collecting tweets from interval: 259\n",
      "1341\n",
      "Collecting tweets from interval: 260\n",
      "1266\n",
      "Collecting tweets from interval: 261\n",
      "1321\n",
      "Collecting tweets from interval: 262\n",
      "1190\n",
      "Collecting tweets from interval: 263\n",
      "988\n",
      "Collecting tweets from interval: 264\n",
      "1051\n",
      "Collecting tweets from interval: 265\n",
      "884\n",
      "Collecting tweets from interval: 266\n",
      "911\n",
      "Collecting tweets from interval: 267\n",
      "891\n",
      "Collecting tweets from interval: 268\n",
      "882\n",
      "Collecting tweets from interval: 269\n",
      "883\n",
      "Collecting tweets from interval: 270\n",
      "520\n",
      "Collecting tweets from interval: 271\n",
      "928\n",
      "Collecting tweets from interval: 272\n",
      "886\n",
      "Collecting tweets from interval: 273\n",
      "1139\n",
      "Collecting tweets from interval: 274\n",
      "1088\n",
      "Collecting tweets from interval: 275\n",
      "18\n",
      "Collecting tweets from interval: 276\n",
      "1300\n",
      "Collecting tweets from interval: 277\n",
      "1436\n",
      "Collecting tweets from interval: 278\n",
      "1354\n",
      "Collecting tweets from interval: 279\n",
      "1542\n",
      "Collecting tweets from interval: 280\n",
      "1895\n",
      "Collecting tweets from interval: 281\n",
      "1553\n",
      "Collecting tweets from interval: 282\n",
      "1470\n",
      "Collecting tweets from interval: 283\n",
      "1417\n",
      "Collecting tweets from interval: 284\n",
      "1242\n",
      "Collecting tweets from interval: 285\n",
      "140\n",
      "Collecting tweets from interval: 286\n",
      "1220\n",
      "Collecting tweets from interval: 287\n",
      "615\n",
      "Collecting tweets from interval: 288\n",
      "1023\n",
      "Collecting tweets from interval: 289\n",
      "1014\n",
      "Collecting tweets from interval: 290\n",
      "869\n",
      "Collecting tweets from interval: 291\n",
      "870\n",
      "Collecting tweets from interval: 292\n",
      "856\n",
      "Collecting tweets from interval: 293\n",
      "944\n",
      "Collecting tweets from interval: 294\n",
      "140\n",
      "Collecting tweets from interval: 295\n",
      "1000\n",
      "Collecting tweets from interval: 296\n",
      "1230\n",
      "Collecting tweets from interval: 297\n",
      "1233\n",
      "Collecting tweets from interval: 298\n",
      "1190\n",
      "Collecting tweets from interval: 299\n",
      "1230\n",
      "Collecting tweets from interval: 300\n",
      "1431\n",
      "Collecting tweets from interval: 301\n",
      "1463\n",
      "Collecting tweets from interval: 302\n",
      "1718\n",
      "Collecting tweets from interval: 303\n",
      "1834\n",
      "Collecting tweets from interval: 304\n",
      "1645\n",
      "Collecting tweets from interval: 305\n",
      "1630\n",
      "Collecting tweets from interval: 306\n",
      "1448\n",
      "Collecting tweets from interval: 307\n",
      "1325\n",
      "Collecting tweets from interval: 308\n",
      "1385\n",
      "Collecting tweets from interval: 309\n",
      "1316\n",
      "Collecting tweets from interval: 310\n",
      "1368\n",
      "Collecting tweets from interval: 311\n",
      "1238\n",
      "Collecting tweets from interval: 312\n",
      "1068\n",
      "Collecting tweets from interval: 313\n",
      "1002\n",
      "Collecting tweets from interval: 314\n",
      "940\n",
      "Collecting tweets from interval: 315\n",
      "876\n",
      "Collecting tweets from interval: 316\n",
      "40\n",
      "Collecting tweets from interval: 317\n",
      "974\n",
      "Collecting tweets from interval: 318\n",
      "980\n",
      "Collecting tweets from interval: 319\n",
      "1034\n",
      "Collecting tweets from interval: 320\n",
      "1206\n",
      "Collecting tweets from interval: 321\n",
      "1146\n",
      "Collecting tweets from interval: 322\n",
      "658\n",
      "Collecting tweets from interval: 323\n",
      "1252\n",
      "Collecting tweets from interval: 324\n",
      "1258\n",
      "Collecting tweets from interval: 325\n",
      "1486\n",
      "Collecting tweets from interval: 326\n",
      "1837\n",
      "Collecting tweets from interval: 327\n",
      "1734\n",
      "Collecting tweets from interval: 328\n",
      "1716\n",
      "Collecting tweets from interval: 329\n",
      "1542\n",
      "Collecting tweets from interval: 330\n",
      "1316\n",
      "Collecting tweets from interval: 331\n",
      "1291\n",
      "Collecting tweets from interval: 332\n",
      "1246\n",
      "Collecting tweets from interval: 333\n",
      "1359\n",
      "Collecting tweets from interval: 334\n",
      "1557\n",
      "Collecting tweets from interval: 335\n",
      "1337\n",
      "Collecting tweets from interval: 336\n",
      "1090\n",
      "Collecting tweets from interval: 337\n",
      "1083\n",
      "Collecting tweets from interval: 338\n",
      "940\n",
      "Collecting tweets from interval: 339\n",
      "935\n",
      "Collecting tweets from interval: 340\n",
      "837\n",
      "Collecting tweets from interval: 341\n",
      "839\n",
      "Collecting tweets from interval: 342\n",
      "926\n",
      "Collecting tweets from interval: 343\n",
      "903\n",
      "Collecting tweets from interval: 344\n",
      "989\n",
      "Collecting tweets from interval: 345\n",
      "1050\n",
      "Collecting tweets from interval: 346\n",
      "1021\n",
      "Collecting tweets from interval: 347\n",
      "983\n",
      "Collecting tweets from interval: 348\n",
      "1010\n",
      "Collecting tweets from interval: 349\n",
      "1225\n",
      "Collecting tweets from interval: 350\n",
      "1218\n",
      "Collecting tweets from interval: 351\n",
      "1242\n",
      "Collecting tweets from interval: 352\n",
      "931\n",
      "Collecting tweets from interval: 353\n",
      "1360\n",
      "Collecting tweets from interval: 354\n",
      "676\n",
      "Collecting tweets from interval: 355\n",
      "1233\n",
      "Collecting tweets from interval: 356\n",
      "1129\n",
      "Collecting tweets from interval: 357\n",
      "1065\n",
      "Collecting tweets from interval: 358\n",
      "1070\n",
      "Collecting tweets from interval: 359\n",
      "1001\n",
      "Collecting tweets from interval: 360\n",
      "990\n",
      "Collecting tweets from interval: 361\n",
      "962\n",
      "Collecting tweets from interval: 362\n",
      "1189\n",
      "Collecting tweets from interval: 363\n",
      "1138\n",
      "Collecting tweets from interval: 364\n",
      "1080\n",
      "Collecting tweets from interval: 365\n",
      "1074\n",
      "Collecting tweets from interval: 366\n",
      "635\n",
      "Collecting tweets from interval: 367\n",
      "1586\n",
      "Collecting tweets from interval: 368\n",
      "1468\n",
      "Collecting tweets from interval: 369\n",
      "958\n",
      "Collecting tweets from interval: 370\n",
      "1209\n",
      "Collecting tweets from interval: 371\n",
      "1222\n",
      "Collecting tweets from interval: 372\n",
      "46\n",
      "Collecting tweets from interval: 373\n",
      "1306\n",
      "Collecting tweets from interval: 374\n",
      "1419\n",
      "Collecting tweets from interval: 375\n",
      "1626\n",
      "Collecting tweets from interval: 376\n",
      "1560\n",
      "Collecting tweets from interval: 377\n",
      "1457\n",
      "Collecting tweets from interval: 378\n",
      "1521\n",
      "Collecting tweets from interval: 379\n",
      "1172\n",
      "Collecting tweets from interval: 380\n",
      "1240\n",
      "Collecting tweets from interval: 381\n",
      "1266\n",
      "Collecting tweets from interval: 382\n",
      "1019\n",
      "Collecting tweets from interval: 383\n",
      "1275\n",
      "Collecting tweets from interval: 384\n",
      "1201\n",
      "Collecting tweets from interval: 385\n",
      "1225\n",
      "Collecting tweets from interval: 386\n",
      "1160\n",
      "Collecting tweets from interval: 387\n",
      "1182\n",
      "Collecting tweets from interval: 388\n",
      "1000\n",
      "Collecting tweets from interval: 389\n",
      "40\n",
      "Collecting tweets from interval: 390\n",
      "1009\n",
      "Collecting tweets from interval: 391\n",
      "1129\n",
      "Collecting tweets from interval: 392\n",
      "1238\n",
      "Collecting tweets from interval: 393\n",
      "1367\n",
      "Collecting tweets from interval: 394\n",
      "805\n",
      "Collecting tweets from interval: 395\n",
      "879\n",
      "Collecting tweets from interval: 396\n",
      "1784\n",
      "Collecting tweets from interval: 397\n",
      "635\n",
      "Collecting tweets from interval: 398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960\n",
      "Collecting tweets from interval: 399\n",
      "1933\n",
      "Collecting tweets from interval: 400\n",
      "1398\n",
      "Collecting tweets from interval: 401\n",
      "80\n",
      "Collecting tweets from interval: 402\n",
      "1850\n",
      "Collecting tweets from interval: 403\n",
      "1687\n",
      "Collecting tweets from interval: 404\n",
      "1638\n",
      "Collecting tweets from interval: 405\n",
      "1656\n",
      "Collecting tweets from interval: 406\n",
      "1720\n",
      "Collecting tweets from interval: 407\n",
      "1475\n",
      "Collecting tweets from interval: 408\n",
      "1338\n",
      "Collecting tweets from interval: 409\n",
      "1200\n",
      "Collecting tweets from interval: 410\n",
      "1162\n",
      "Collecting tweets from interval: 411\n",
      "1206\n",
      "Collecting tweets from interval: 412\n",
      "1050\n",
      "Collecting tweets from interval: 413\n",
      "1005\n",
      "Collecting tweets from interval: 414\n",
      "1164\n",
      "Collecting tweets from interval: 415\n",
      "1196\n",
      "Collecting tweets from interval: 416\n",
      "1305\n",
      "Collecting tweets from interval: 417\n",
      "79\n",
      "Collecting tweets from interval: 418\n",
      "1731\n",
      "Collecting tweets from interval: 419\n",
      "1879\n",
      "Collecting tweets from interval: 420\n",
      "1989\n",
      "Collecting tweets from interval: 421\n",
      "2203\n",
      "Collecting tweets from interval: 422\n",
      "2414\n",
      "Collecting tweets from interval: 423\n",
      "2300\n",
      "Collecting tweets from interval: 424\n",
      "2226\n",
      "Collecting tweets from interval: 425\n",
      "2235\n",
      "Collecting tweets from interval: 426\n",
      "2044\n",
      "Collecting tweets from interval: 427\n",
      "1885\n",
      "Collecting tweets from interval: 428\n",
      "1772\n",
      "Collecting tweets from interval: 429\n",
      "1706\n",
      "Collecting tweets from interval: 430\n",
      "1509\n",
      "Collecting tweets from interval: 431\n",
      "1402\n",
      "Collecting tweets from interval: 432\n",
      "1363\n",
      "Collecting tweets from interval: 433\n",
      "1145\n",
      "Collecting tweets from interval: 434\n",
      "1119\n",
      "Collecting tweets from interval: 435\n",
      "1192\n",
      "Collecting tweets from interval: 436\n",
      "1092\n",
      "Collecting tweets from interval: 437\n",
      "760\n",
      "Collecting tweets from interval: 438\n",
      "1149\n",
      "Collecting tweets from interval: 439\n",
      "1277\n",
      "Collecting tweets from interval: 440\n",
      "1472\n",
      "Collecting tweets from interval: 441\n",
      "1430\n",
      "Collecting tweets from interval: 442\n",
      "1362\n",
      "Collecting tweets from interval: 443\n",
      "1418\n",
      "Collecting tweets from interval: 444\n",
      "938\n",
      "Collecting tweets from interval: 445\n",
      "1685\n",
      "Collecting tweets from interval: 446\n",
      "1791\n",
      "Collecting tweets from interval: 447\n",
      "1688\n",
      "Collecting tweets from interval: 448\n",
      "1694\n",
      "Collecting tweets from interval: 449\n",
      "1758\n",
      "Collecting tweets from interval: 450\n",
      "1553\n",
      "Collecting tweets from interval: 451\n",
      "1490\n",
      "Collecting tweets from interval: 452\n",
      "1372\n",
      "Collecting tweets from interval: 453\n",
      "1448\n",
      "Collecting tweets from interval: 454\n",
      "1345\n",
      "Collecting tweets from interval: 455\n",
      "1393\n",
      "Collecting tweets from interval: 456\n",
      "1287\n",
      "Collecting tweets from interval: 457\n",
      "1176\n",
      "Collecting tweets from interval: 458\n",
      "1112\n",
      "Collecting tweets from interval: 459\n",
      "1065\n",
      "Collecting tweets from interval: 460\n",
      "1097\n",
      "Collecting tweets from interval: 461\n",
      "1087\n",
      "Collecting tweets from interval: 462\n",
      "1102\n",
      "Collecting tweets from interval: 463\n",
      "1086\n",
      "Collecting tweets from interval: 464\n",
      "1395\n",
      "Collecting tweets from interval: 465\n",
      "1319\n",
      "Collecting tweets from interval: 466\n",
      "1341\n",
      "Collecting tweets from interval: 467\n",
      "1314\n",
      "Collecting tweets from interval: 468\n",
      "1384\n",
      "Collecting tweets from interval: 469\n",
      "797\n",
      "Collecting tweets from interval: 470\n",
      "1038\n",
      "Collecting tweets from interval: 471\n",
      "1758\n",
      "Collecting tweets from interval: 472\n",
      "1789\n",
      "Collecting tweets from interval: 473\n",
      "1837\n",
      "Collecting tweets from interval: 474\n",
      "1596\n",
      "Collecting tweets from interval: 475\n",
      "1530\n",
      "Collecting tweets from interval: 476\n",
      "1634\n",
      "Collecting tweets from interval: 477\n",
      "2003\n",
      "Collecting tweets from interval: 478\n",
      "680\n",
      "Collecting tweets from interval: 479\n",
      "1413\n",
      "Collecting tweets from interval: 480\n",
      "1187\n",
      "Collecting tweets from interval: 481\n",
      "1230\n",
      "Collecting tweets from interval: 482\n",
      "1616\n",
      "Collecting tweets from interval: 483\n",
      "1684\n",
      "Collecting tweets from interval: 484\n",
      "399\n",
      "Collecting tweets from interval: 485\n",
      "1254\n",
      "Collecting tweets from interval: 486\n",
      "1361\n",
      "Collecting tweets from interval: 487\n",
      "1360\n",
      "Collecting tweets from interval: 488\n",
      "637\n",
      "Collecting tweets from interval: 489\n",
      "1588\n",
      "Collecting tweets from interval: 490\n",
      "1520\n",
      "Collecting tweets from interval: 491\n",
      "1699\n",
      "Collecting tweets from interval: 492\n",
      "1766\n",
      "Collecting tweets from interval: 493\n",
      "553\n",
      "Collecting tweets from interval: 494\n",
      "2273\n",
      "Collecting tweets from interval: 495\n",
      "1961\n",
      "Collecting tweets from interval: 496\n",
      "2003\n",
      "Collecting tweets from interval: 497\n",
      "1975\n",
      "Collecting tweets from interval: 498\n",
      "620\n",
      "Collecting tweets from interval: 499\n",
      "2004\n",
      "Collecting tweets from interval: 500\n",
      "1777\n",
      "Collecting tweets from interval: 501\n",
      "1604\n",
      "Collecting tweets from interval: 502\n",
      "1604\n",
      "Collecting tweets from interval: 503\n",
      "1437\n",
      "Collecting tweets from interval: 504\n",
      "3178\n",
      "Collecting tweets from interval: 505\n",
      "2838\n",
      "Collecting tweets from interval: 506\n",
      "240\n",
      "Collecting tweets from interval: 507\n",
      "2700\n",
      "Collecting tweets from interval: 508\n",
      "2240\n",
      "Collecting tweets from interval: 509\n",
      "1804\n",
      "Collecting tweets from interval: 510\n",
      "1849\n",
      "Collecting tweets from interval: 511\n",
      "1837\n",
      "Collecting tweets from interval: 512\n",
      "1969\n",
      "Collecting tweets from interval: 513\n",
      "1786\n",
      "Collecting tweets from interval: 514\n",
      "1080\n",
      "Collecting tweets from interval: 515\n",
      "1000\n",
      "Collecting tweets from interval: 516\n",
      "2094\n",
      "Collecting tweets from interval: 517\n",
      "3158\n",
      "Collecting tweets from interval: 518\n",
      "380\n",
      "Collecting tweets from interval: 519\n",
      "400\n",
      "Collecting tweets from interval: 520\n",
      "2619\n",
      "Collecting tweets from interval: 521\n",
      "2442\n",
      "Collecting tweets from interval: 522\n",
      "397\n",
      "Collecting tweets from interval: 523\n",
      "1963\n",
      "Collecting tweets from interval: 524\n",
      "1787\n",
      "Collecting tweets from interval: 525\n",
      "1646\n",
      "Collecting tweets from interval: 526\n",
      "1603\n",
      "Collecting tweets from interval: 527\n",
      "1465\n",
      "Collecting tweets from interval: 528\n",
      "1359\n",
      "Collecting tweets from interval: 529\n",
      "1354\n",
      "Collecting tweets from interval: 530\n",
      "1150\n",
      "Collecting tweets from interval: 531\n",
      "1150\n",
      "Collecting tweets from interval: 532\n",
      "817\n",
      "Collecting tweets from interval: 533\n",
      "1079\n",
      "Collecting tweets from interval: 534\n",
      "1097\n",
      "Collecting tweets from interval: 535\n",
      "1095\n",
      "Collecting tweets from interval: 536\n",
      "1267\n",
      "Collecting tweets from interval: 537\n",
      "1228\n",
      "Collecting tweets from interval: 538\n",
      "219\n",
      "Collecting tweets from interval: 539\n",
      "1399\n",
      "Collecting tweets from interval: 540\n",
      "1404\n",
      "Collecting tweets from interval: 541\n",
      "1552\n",
      "Collecting tweets from interval: 542\n",
      "1676\n",
      "Collecting tweets from interval: 543\n",
      "1662\n",
      "Collecting tweets from interval: 544\n",
      "1731\n",
      "Collecting tweets from interval: 545\n",
      "1638\n",
      "Collecting tweets from interval: 546\n",
      "1578\n",
      "Collecting tweets from interval: 547\n",
      "1503\n",
      "Collecting tweets from interval: 548\n",
      "1706\n",
      "Collecting tweets from interval: 549\n",
      "1682\n",
      "Collecting tweets from interval: 550\n",
      "250\n",
      "Collecting tweets from interval: 551\n",
      "1385\n",
      "Collecting tweets from interval: 552\n",
      "1292\n",
      "Collecting tweets from interval: 553\n",
      "1298\n",
      "Collecting tweets from interval: 554\n",
      "1281\n",
      "Collecting tweets from interval: 555\n",
      "1097\n",
      "Collecting tweets from interval: 556\n",
      "1156\n",
      "Collecting tweets from interval: 557\n",
      "57\n",
      "Collecting tweets from interval: 558\n",
      "1299\n",
      "Collecting tweets from interval: 559\n",
      "1331\n",
      "Collecting tweets from interval: 560\n",
      "1573\n",
      "Collecting tweets from interval: 561\n",
      "1710\n",
      "Collecting tweets from interval: 562\n",
      "1701\n",
      "Collecting tweets from interval: 563\n",
      "1643\n",
      "Collecting tweets from interval: 564\n",
      "498\n",
      "Collecting tweets from interval: 565\n",
      "2099\n",
      "Collecting tweets from interval: 566\n",
      "2107\n",
      "Collecting tweets from interval: 567\n",
      "2050\n",
      "Collecting tweets from interval: 568\n",
      "2124\n",
      "Collecting tweets from interval: 569\n",
      "2179\n",
      "Collecting tweets from interval: 570\n",
      "2029\n",
      "Collecting tweets from interval: 571\n",
      "1275\n",
      "Collecting tweets from interval: 572\n",
      "1691\n",
      "Collecting tweets from interval: 573\n",
      "1588\n",
      "Collecting tweets from interval: 574\n",
      "1589\n",
      "Collecting tweets from interval: 575\n",
      "760\n",
      "Collecting tweets from interval: 576\n",
      "1603\n",
      "Collecting tweets from interval: 577\n",
      "1318\n",
      "Collecting tweets from interval: 578\n",
      "1281\n",
      "Collecting tweets from interval: 579\n",
      "1369\n",
      "Collecting tweets from interval: 580\n",
      "1253\n",
      "Collecting tweets from interval: 581\n"
     ]
    }
   ],
   "source": [
    "tmp = Tweet_Collecter(init_browser = False,browser=browser)\n",
    "tmp = tmp.collect_tweets(start_date=datetime.datetime(2019,6,1), end_date= datetime.datetime(2019,7,31),\n",
    "                         approx_tweets_per_interval=5000, interval_mins=60,filename='bitcoin',\n",
    "                         save_folder_name='bitcoin', filters=['#btc','bitcoin'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "\n",
    "\n",
    "driver = browser\n",
    "url1 = 'https://twitter.com/search?f=tweets&q=btc%20OR%20bitcoin%20since%3A2015-05-01%20until%3A2015-05-02&src=typd' \n",
    "driver.get(url1)\n",
    "\n",
    "\n",
    "class wait_for_more_than_n_elements_to_be_present(object):\n",
    "    def __init__(self, locator, count):\n",
    "        self.locator = locator\n",
    "        self.count = count\n",
    " \n",
    "    def __call__(self, driver):\n",
    "        try:\n",
    "            elements = EC._find_elements(driver, self.locator)\n",
    "            return len(elements) > self.count\n",
    "        except StaleElementReferenceException:\n",
    "            return False\n",
    "wait = WebDriverWait(driver, 10)\n",
    "try:\n",
    "    # wait until the first search result is found. Search results will be tweets, which are html list items and have the class='data-item-id':\n",
    "    wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"li[data-item-id]\")))\n",
    "\n",
    "    # scroll down to the last tweet until there are no more tweets:\n",
    "    number_of_tweets=0\n",
    "    while number_of_tweets<200:\n",
    "\n",
    "        # extract all the tweets:\n",
    "        tweets = driver.find_elements_by_css_selector(\"li[data-item-id]\")\n",
    "\n",
    "        # find number of visible tweets:\n",
    "        number_of_tweets = len(tweets)\n",
    "\n",
    "        # keep scrolling:\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", tweets[-1])\n",
    "\n",
    "        try:\n",
    "            # wait for more tweets to be visible:\n",
    "            wait.until(wait_for_more_than_n_elements_to_be_present(\n",
    "                (By.CSS_SELECTOR, \"li[data-item-id]\"), number_of_tweets))\n",
    "            print(number_of_tweets)\n",
    "        except TimeoutException:\n",
    "            # if no more are visible the \"wait.until\" call will timeout. Catch the exception and exit the while loop:\n",
    "            print(number_of_tweets)\n",
    "            break\n",
    "\n",
    "    # extract the html for the whole lot:\n",
    "    page_source = driver.page_source\n",
    "\n",
    "except TimeoutException:\n",
    "    print(number_of_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ben\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\Ben\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "soup = bs4.BeautifulSoup(page_source)\n",
    "\n",
    "tweets = []\n",
    "for li in soup.find_all(\"li\", class_='js-stream-item'):\n",
    "\n",
    "    # If our li doesn't have a tweet-id, we skip it as it's not going to be a tweet.\n",
    "    if 'data-item-id' not in li.attrs:\n",
    "        continue\n",
    "\n",
    "    else:\n",
    "        tweet = {\n",
    "            'tweet_id': li['data-item-id'],\n",
    "            'text': None,\n",
    "            'user_id': None,\n",
    "            'user_screen_name': None,\n",
    "            'user_name': None,\n",
    "            'created_at': None,\n",
    "            'retweets': 0,\n",
    "            'likes': 0,\n",
    "            'replies': 0\n",
    "        }\n",
    "\n",
    "    # Tweet Text\n",
    "    text_p = li.find(\"p\", class_=\"tweet-text\")\n",
    "    if text_p is not None:\n",
    "        tweet['text'] = text_p.get_text()\n",
    "\n",
    "    # Tweet User ID, User Screen Name, User Name\n",
    "    user_details_div = li.find(\"div\", class_=\"tweet\")\n",
    "    if user_details_div is not None:\n",
    "        tweet['user_id'] = user_details_div['data-user-id']\n",
    "        tweet['user_screen_name'] = user_details_div['data-screen-name']\n",
    "        tweet['user_name'] = user_details_div['data-name']\n",
    "\n",
    "    # Tweet date\n",
    "    date_span = li.find(\"span\", class_=\"_timestamp\")\n",
    "    if date_span is not None:\n",
    "        tweet['created_at'] = float(date_span['data-time-ms'])\n",
    "\n",
    "    # Tweet Retweets\n",
    "    retweet_span = li.select(\"span.ProfileTweet-action--retweet > span.ProfileTweet-actionCount\")\n",
    "    if retweet_span is not None and len(retweet_span) > 0:\n",
    "            tweet['retweets'] = int(retweet_span[0]['data-tweet-stat-count'])\n",
    "\n",
    "    # Tweet Likes\n",
    "    like_span = li.select(\"span.ProfileTweet-action--favorite > span.ProfileTweet-actionCount\")\n",
    "    if like_span is not None and len(like_span) > 0:\n",
    "        tweet['likes'] = int(like_span[0]['data-tweet-stat-count'])\n",
    "\n",
    "    # Tweet Replies\n",
    "    reply_span = li.select(\"span.ProfileTweet-action--reply > span.ProfileTweet-actionCount\")\n",
    "    if reply_span is not None and len(reply_span) > 0:\n",
    "        tweet['replies'] = int(reply_span[0]['data-tweet-stat-count'])\n",
    "\n",
    "    tweets.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>likes</th>\n",
       "      <th>replies</th>\n",
       "      <th>retweets</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_screen_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.430525e+12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10002</td>\n",
       "      <td>#DNotes co-founder Alan Yong will be attending...</td>\n",
       "      <td>594290197749194752</td>\n",
       "      <td>2306894348</td>\n",
       "      <td>DNotes</td>\n",
       "      <td>DNotesCoin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.430525e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Helllllsssssss yeaaaaa!!!!!!! Nicki here I com...</td>\n",
       "      <td>594290166468112384</td>\n",
       "      <td>264383298</td>\n",
       "      <td>SHOORRTTYYY!!!</td>\n",
       "      <td>BOOM_BTC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.430525e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bitcoin : quelle ralit pour les utilisateurs...</td>\n",
       "      <td>594290119684845568</td>\n",
       "      <td>3152422890</td>\n",
       "      <td>CAWAM</td>\n",
       "      <td>CAWAMcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.430525e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>New post: Bitcoin Slowly Getting into Mainstre...</td>\n",
       "      <td>594290086281228288</td>\n",
       "      <td>2387831629</td>\n",
       "      <td>CoinBorse NEWS</td>\n",
       "      <td>CoinBorse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.430525e+12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>New post: BTC - 247 http://hodl.cz</td>\n",
       "      <td>594290083072581632</td>\n",
       "      <td>2387831629</td>\n",
       "      <td>CoinBorse NEWS</td>\n",
       "      <td>CoinBorse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     created_at  likes  replies  retweets  \\\n",
       "0  1.430525e+12      4        0     10002   \n",
       "1  1.430525e+12      0        0         0   \n",
       "2  1.430525e+12      0        0         0   \n",
       "3  1.430525e+12      0        0         0   \n",
       "4  1.430525e+12      0        0         0   \n",
       "\n",
       "                                                text            tweet_id  \\\n",
       "0  #DNotes co-founder Alan Yong will be attending...  594290197749194752   \n",
       "1  Helllllsssssss yeaaaaa!!!!!!! Nicki here I com...  594290166468112384   \n",
       "2  Bitcoin : quelle ralit pour les utilisateurs...  594290119684845568   \n",
       "3  New post: Bitcoin Slowly Getting into Mainstre...  594290086281228288   \n",
       "4                New post: BTC - 247 http://hodl.cz  594290083072581632   \n",
       "\n",
       "      user_id       user_name user_screen_name  \n",
       "0  2306894348          DNotes       DNotesCoin  \n",
       "1   264383298  SHOORRTTYYY!!!         BOOM_BTC  \n",
       "2  3152422890           CAWAM         CAWAMcom  \n",
       "3  2387831629  CoinBorse NEWS        CoinBorse  \n",
       "4  2387831629  CoinBorse NEWS        CoinBorse  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.DataFrame(tweets)\n",
    "tmp['created_at'].apply(lambda x: datetime.datetime.utcfromtimestamp(int(x/1000)))\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2019-01-01T10:20:00'"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = datetime.datetime(2019,1,1,10,20)\n",
    "time2 = datetime.datetime(2019,1,1,11,50)\n",
    "\n",
    "interval_mins=20\n",
    "tmp = pd.date_range(start = time1, end = time2, freq = str(interval_mins)+'min')\n",
    "tmp[0].isoformat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 7, 21, 10, 20, 57)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.utcfromtimestamp(1563704457)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 7, 20, 0, 0)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.datetime.today().date()\n",
    "datetime.datetime(tmp.year,tmp.month,tmp.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets_df= pd.DataFrame(data=np.array([tweet_texts,dates,user_names,user_ids]).T,\n",
    "                 columns = ['text','created_at','user_name','user_id'])\n",
    "            \n",
    "tweets_df['followers'] = tweets_df['user_id'].apply(lambda x: api.get_user(x)._json['followers_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#DNotes co-founder Alan Yong will be attending...</td>\n",
       "      <td>2015-05-01 23:59:59</td>\n",
       "      <td>DNotesCoin</td>\n",
       "      <td>2306894348</td>\n",
       "      <td>7088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Helllllsssssss yeaaaaa!!!!!!! Nicki here I com...</td>\n",
       "      <td>2015-05-01 23:59:51</td>\n",
       "      <td>BOOM_BTC</td>\n",
       "      <td>264383298</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitcoin : quelle ralit pour les utilisateurs...</td>\n",
       "      <td>2015-05-01 23:59:40</td>\n",
       "      <td>CAWAMcom</td>\n",
       "      <td>3152422890</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New post: Bitcoin Slowly Getting into Mainstre...</td>\n",
       "      <td>2015-05-01 23:59:32</td>\n",
       "      <td>CoinBorse</td>\n",
       "      <td>2387831629</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New post: BTC - 247 http://hodl.cz</td>\n",
       "      <td>2015-05-01 23:59:31</td>\n",
       "      <td>CoinBorse</td>\n",
       "      <td>2387831629</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           created_at  \\\n",
       "0  #DNotes co-founder Alan Yong will be attending...  2015-05-01 23:59:59   \n",
       "1  Helllllsssssss yeaaaaa!!!!!!! Nicki here I com...  2015-05-01 23:59:51   \n",
       "2  Bitcoin : quelle ralit pour les utilisateurs...  2015-05-01 23:59:40   \n",
       "3  New post: Bitcoin Slowly Getting into Mainstre...  2015-05-01 23:59:32   \n",
       "4                New post: BTC - 247 http://hodl.cz   2015-05-01 23:59:31   \n",
       "\n",
       "    user_name     user_id  followers  \n",
       "0  DNotesCoin  2306894348       7088  \n",
       "1    BOOM_BTC   264383298        628  \n",
       "2    CAWAMcom  3152422890        876  \n",
       "3   CoinBorse  2387831629        109  \n",
       "4   CoinBorse  2387831629        109  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.to_csv(r'C:\\Users\\Ben\\Documents\\2019 Summer\\TradingAlgo\\Tweets\\temp\\bitcoin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# body = browser.find_element_by_tag_name('body')\n",
    "# reached_bottom = False\n",
    "# # While not reached_bottom:\n",
    "# for i in range(10):\n",
    "#     body.send_keys(Keys.PAGE_DOWN)\n",
    "#     print(body.size)\n",
    "#     time.sleep(0.001)\n",
    "# #     if:\n",
    "# #         reached_bottom=True\n",
    "    \n",
    "\n",
    "tweets = browser.find_elements_by_class_name('js-actionable-tweet')\n",
    "tweet_texts = [tweet.find_element_by_class_name('js-tweet-text-container').text for tweet in tweets]\n",
    "user_names = [tweet.get_attribute('data-screen-name') for tweet in tweets]\n",
    "user_ids = [tweet.get_attribute('data-user-id') for tweet in tweets]\n",
    "timestamps = [tweet.find_element_by_class_name('js-short-timestamp').get_attribute('data-time') for tweet in tweets]\n",
    "dates = [datetime.datetime.utcfromtimestamp(int(ts)) for ts in timestamps]\n",
    "\n",
    "# tweets[0].find_element_by_class_name('username').text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp= pd.DataFrame(data=np.array([tweet_texts,dates,user_names,user_ids]).T,\n",
    "                 columns = ['text','created_at','user_name','user_id'])\n",
    "tmp['followers'] = tmp['user_id'].apply(lambda x: api.get_user(x)._json['followers_count'])\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "220"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "# print(initial_height)\n",
    "# while browser.execute_script(\"return document.body.scrollHeight\") ==initial_height:\n",
    "#     body.send_keys(Keys.PAGE_DOWN)\n",
    "#     time.sleep(0.5)\n",
    "#     print(browser.execute_script(\"return document.body.scrollHeight\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#DNotes co-founder Alan Yong will be attending...</td>\n",
       "      <td>2015-05-01 23:59:59</td>\n",
       "      <td>DNotesCoin</td>\n",
       "      <td>2306894348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Helllllsssssss yeaaaaa!!!!!!! Nicki here I com...</td>\n",
       "      <td>2015-05-01 23:59:51</td>\n",
       "      <td>BOOM_BTC</td>\n",
       "      <td>264383298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bitcoin : quelle ralit pour les utilisateurs...</td>\n",
       "      <td>2015-05-01 23:59:40</td>\n",
       "      <td>CAWAMcom</td>\n",
       "      <td>3152422890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New post: Bitcoin Slowly Getting into Mainstre...</td>\n",
       "      <td>2015-05-01 23:59:32</td>\n",
       "      <td>CoinBorse</td>\n",
       "      <td>2387831629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New post: BTC - 247 http://hodl.cz</td>\n",
       "      <td>2015-05-01 23:59:31</td>\n",
       "      <td>CoinBorse</td>\n",
       "      <td>2387831629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text           created_at  \\\n",
       "0  #DNotes co-founder Alan Yong will be attending...  2015-05-01 23:59:59   \n",
       "1  Helllllsssssss yeaaaaa!!!!!!! Nicki here I com...  2015-05-01 23:59:51   \n",
       "2  Bitcoin : quelle ralit pour les utilisateurs...  2015-05-01 23:59:40   \n",
       "3  New post: Bitcoin Slowly Getting into Mainstre...  2015-05-01 23:59:32   \n",
       "4                New post: BTC - 247 http://hodl.cz   2015-05-01 23:59:31   \n",
       "\n",
       "    user_name     user_id  \n",
       "0  DNotesCoin  2306894348  \n",
       "1    BOOM_BTC   264383298  \n",
       "2    CAWAMcom  3152422890  \n",
       "3   CoinBorse  2387831629  \n",
       "4   CoinBorse  2387831629  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp= pd.DataFrame(data=np.array([tweet_texts,dates,user_names,user_ids]).T,\n",
    "                 columns = ['text','created_at','user_name','user_id'])\n",
    "tmp['followers'] = tmp['user_id'].apply(lambda x: api.get_user(x)._json['followers_count'])\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bitcoin : quelle ralit pour les utilisateurs ? - ITespresso.fr  #bitcoin http://bit.ly/1JfvM12 '"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.iloc[2,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tweet_Collecter(object):\n",
    "    \n",
    "    def __init__(self, init_browser=True, browser=None):\n",
    "        \n",
    "        import os\n",
    "        import math\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from selenium.webdriver.chrome.options import Options\n",
    "        from selenium import webdriver\n",
    "        import tweepy\n",
    "        import time\n",
    "        import datetime\n",
    "        import requests\n",
    "        \n",
    "        self.init_browser= init_browser\n",
    "        \n",
    "        self.C_Key = 'ILYTd5Abkw85OKTd5sAbSpPdC'\n",
    "        self.C_Secret='1hHTjqyq5Kitt3b5gka6uPMkvKzuz5wO7C63HcRLP5v2mHUtz6'\n",
    "        self.A_Token='2758135350-UfWPEgJPQJTCHvCQRQEzcavyl45mcwwLkRnWWBi'\n",
    "        self.A_Token_Secret='LKa0IlzGhWdLKgzhATUtFx0kM5AGG6lAWBUoOEP1lKj9g'\n",
    "\n",
    "        auth = tweepy.OAuthHandler(consumer_key=C_Key, consumer_secret=C_Secret)\n",
    "        auth.set_access_token(A_Token, A_Token_Secret)\n",
    "        self.auth = auth\n",
    "        \n",
    "        self.api = tweepy.API(auth)\n",
    "        if init_browser:\n",
    "            chrome_option = Options()\n",
    "            chrome_option.add_argument(r'user-data-dir=C:\\Users\\Ben\\AppData\\Local\\Google\\Chrome\\User Data\\Default')\n",
    "            chrome_option.add_argument(\"--no-sandbox\")\n",
    "            chrome_option.add_argument(\"--disable-dev-shm-usage\")\n",
    "            chrome_option.add_argument(\"--headless\")\n",
    "            self.browser = webdriver.Chrome(executable_path=r'C:\\Users\\Ben\\Documents\\Varsity Surf\\chromedriver_win32\\chromedriver.exe',\n",
    "                                            chrome_options=chrome_option)\n",
    "        else:\n",
    "            self.browser = browser\n",
    "    \n",
    "    def collect_tweets(self, filters = ['#btc', 'bitcoin'], start_date=datetime.datetime.today()-datetime.timedelta(days=1),\n",
    "                       end_date= datetime.datetime.today(), approx_tweets_per_interval = 200, interval_mins=20,\n",
    "                      save_folder_name='temp', filename='bitcoin', round_interval = True):\n",
    "    \n",
    "        browser = self.browser\n",
    "        api = self.api\n",
    "        \n",
    "        if round_interval:\n",
    "            start_date = start_date - datetime.timedelta(minutes=start_date.minute % interval_mins,\n",
    "                                 seconds= start_date.second,\n",
    "                                 microseconds=start_date.microsecond)\n",
    "\n",
    "        if start_date>end_date:\n",
    "            raise Exception('Start date must be after end date')\n",
    "\n",
    "        print('Calculating tweet ids to be collected...')\n",
    "        ################### Find id of tweet exactly 24 hours later\n",
    "        since_datetime = start_date.date()\n",
    "        since_datetime = datetime.datetime(since_datetime.year, since_datetime.month, since_datetime.day)\n",
    "        until_datetime = (start_date + datetime.timedelta(days=1)).date()\n",
    "        until_datetime = datetime.datetime(until_datetime.year, until_datetime.month, until_datetime.day)\n",
    "        end_datetime = end_date.date()\n",
    "        end_datetime = datetime.datetime(end_datetime.year, end_datetime.month, end_datetime.day)\n",
    "\n",
    "        since_date = since_datetime.isoformat()[:10]\n",
    "        until_date = until_datetime.isoformat()[:10]\n",
    "\n",
    "\n",
    "        filters = [fil.replace('#','%23') for fil in filters]\n",
    "        self.filters = filters\n",
    "        query_filters = str('%20OR%20'.join(filters))\n",
    "        query = query_filters + '%20since%3A'+since_date+'%20until%3A'+until_date+'&src=typd'\n",
    "\n",
    "        base_url = 'https://twitter.com/search?f=tweets&q='\n",
    "        url = base_url + query\n",
    "        browser.get(url) \n",
    "        time.sleep(1)\n",
    "\n",
    "\n",
    "        endtweet_id = int(browser.find_elements_by_class_name('js-actionable-tweet')[0].get_attribute('data-tweet-id'))\n",
    "\n",
    "        #################### Find id of last tweet before timeperiod starts\n",
    "\n",
    "        until_datetime2 = start_date.date()\n",
    "        until_datetime2 = datetime.datetime(until_datetime2.year, until_datetime2.month, until_datetime2.day)\n",
    "        until_date2 = until_datetime2.isoformat()[:10]\n",
    "\n",
    "        query = query_filters + '%20until%3A'+until_date2+'%20lang%3Aen&src=typd'\n",
    "\n",
    "        url = base_url + query\n",
    "\n",
    "        browser.get(url) \n",
    "        time.sleep(1)\n",
    "\n",
    "        starttweet_id = int(browser.find_elements_by_class_name('js-actionable-tweet')[0].get_attribute('data-tweet-id'))\n",
    "\n",
    "        #################### calculate tweet id pairs needed to collect correct tweets at each sub-timeperiod\n",
    "\n",
    "\n",
    "        id_interval = (endtweet_id - starttweet_id)/((60*24)/interval_mins)\n",
    "\n",
    "        ##calculate which id to start on and end on\n",
    "        ##start tweet\n",
    "        start_timejump = start_date - since_datetime #difference between time specified to start at and time at which\n",
    "                                               #starttweet_id currently specifies to collect from\n",
    "        start_intervalsjump = int(math.ceil(start_timejump.total_seconds()/(60*interval_mins)))\n",
    "\n",
    "\n",
    "        total_timeperiod_length = end_date - start_date #total length of time over whole specified timeperiod\n",
    "                                                        # enables calculation of how many id intervals need to be collected\n",
    "\n",
    "        num_intervals= math.ceil(total_timeperiod_length.total_seconds()/(60*interval_mins)) #number of intervals to collect\n",
    "\n",
    "        start_id = int(starttweet_id + start_intervalsjump * id_interval)\n",
    "\n",
    "        since_ids= [int(start_id + i*id_interval) for i in range(num_intervals)]\n",
    "        max_ids = [int(x + id_interval) for x in since_ids]\n",
    "        \n",
    "        time_range = pd.date_range(start = start_date, end = end_date, freq = str(interval_mins)+'min')\n",
    "\n",
    "        print('Tweet ids calculated!')\n",
    "\n",
    "        ################## Start tweet collection\n",
    "        filepath_stem = r'C:\\Users\\Ben\\Documents\\2019 Summer\\TradingAlgo\\Tweets\\ '.strip() + save_folder_name + r'\\ '.strip()       \n",
    "        if not os.path.exists(filepath_stem):\n",
    "            os.mkdir(filepath_stem)\n",
    "    \n",
    "        print('Beginning tweet collection:')\n",
    "        iteration_counter=1\n",
    "\n",
    "        for since_id, max_id, timestamp in zip(since_ids,max_ids, time_range): # for each subtimeperiod/interval of tweets\n",
    "\n",
    "            print('Collecting tweets from interval:',iteration_counter)\n",
    "            iteration_counter+=1\n",
    "\n",
    "            query = query_filters + '%20since_id%3A'+str(int(since_id))+'%20max_id%3A'+str(int(max_id))+'&src=typd'\n",
    "            url = base_url + query\n",
    "\n",
    "            browser.get(url) \n",
    "            time.sleep(1)\n",
    "\n",
    "            #perform browser scrolling to load all tweets\n",
    "            SCROLL_PAUSE_TIME = 0.5\n",
    "\n",
    "            # Get scroll height\n",
    "            last_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "            counter=0\n",
    "            while len(browser.find_elements_by_class_name('js-actionable-tweet'))<approx_tweets_per_interval:\n",
    "                print(len(browser.find_elements_by_class_name('js-actionable-tweet')))\n",
    "                # Scroll down to bottom\n",
    "\n",
    "                browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "                # Wait to load page\n",
    "                time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "                # Calculate new scroll height and compare with last scroll height\n",
    "                new_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    counter +=1\n",
    "                    print('Timeout:',counter)\n",
    "                    if counter==5:\n",
    "                        break\n",
    "                else:\n",
    "                    counter=0\n",
    "                last_height = new_height\n",
    "\n",
    "            ### scrolling complete\n",
    "\n",
    "            #collect tweets and data\n",
    "            tweets = browser.find_elements_by_class_name('js-actionable-tweet')\n",
    "            \n",
    "            tweet_texts = []\n",
    "            user_names = []\n",
    "            user_ids = []\n",
    "            timestamps = []\n",
    "            dates = []\n",
    "            for tweet in tweets:    \n",
    "                try:\n",
    "                    tweet_texts.append(tweet.find_element_by_class_name('js-tweet-text-container').text)\n",
    "                    user_names.append(tweet.get_attribute('data-screen-name'))\n",
    "                    user_ids.append(tweet.get_attribute('data-user-id'))\n",
    "                    timestamps.append(tweet.find_element_by_class_name('js-short-timestamp').get_attribute('data-time'))\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            dates = [datetime.datetime.utcfromtimestamp(int(ts)) for ts in timestamps]\n",
    "            \n",
    "#                 tweet_texts = [tweet.find_element_by_class_name('js-tweet-text-container').text for tweet in tweets]\n",
    "#                 user_names = [tweet.get_attribute('data-screen-name') for tweet in tweets]\n",
    "#                 user_ids = [tweet.get_attribute('data-user-id') for tweet in tweets]\n",
    "#                 timestamps = [tweet.find_element_by_class_name('js-short-timestamp').get_attribute('data-time') for tweet in tweets]\n",
    "#                 dates = [datetime.datetime.utcfromtimestamp(int(ts)) for ts in timestamps]\n",
    "\n",
    "            ### convert data to dataframe\n",
    "\n",
    "            tweets_df= pd.DataFrame(data=np.array([tweet_texts,dates,user_names,user_ids]).T,\n",
    "                 columns = ['text','created_at','user_name','user_id'])\n",
    "\n",
    "            #tweets_df['followers'] = tweets_df['user_id'].apply(lambda x: api.get_user(x)._json['followers_count'])\n",
    "            savefile = filepath_stem + filename + timestamp.isoformat()[:19].replace(':','') +'.csv'\n",
    "\n",
    "            tweets_df.to_csv(savefile)\n",
    "\n",
    "        print('Finished!')\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp['followers'] = tmp['user_id'].apply(lambda x: api.get_user(x)._json['followers_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_id</th>\n",
       "      <th>followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Tsinghua https://bitcoinm...</td>\n",
       "      <td>2015-05-01 23:42:19</td>\n",
       "      <td>toshi_kaseda</td>\n",
       "      <td>2941941391</td>\n",
       "      <td>1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>#Bitcoin Circle Building Its Global Vision Tha...</td>\n",
       "      <td>2015-05-01 23:42:01</td>\n",
       "      <td>CoinfeedIO</td>\n",
       "      <td>2961909107</td>\n",
       "      <td>1336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>My robot is level 3 and I've earned a total of...</td>\n",
       "      <td>2015-05-01 23:41:51</td>\n",
       "      <td>ChrissCoin</td>\n",
       "      <td>3121596999</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Bitcoin dood? Goldman Sachs gelooft er nog in ...</td>\n",
       "      <td>2015-05-01 23:41:30</td>\n",
       "      <td>CAWAMcom</td>\n",
       "      <td>3152422890</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Obsolete ASIC mining... useful to prevent 51% ...</td>\n",
       "      <td>2015-05-01 23:41:23</td>\n",
       "      <td>bonniemck3</td>\n",
       "      <td>2809127089</td>\n",
       "      <td>338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text           created_at  \\\n",
       "215  Tsinghua https://bitcoinm...  2015-05-01 23:42:19   \n",
       "216  #Bitcoin Circle Building Its Global Vision Tha...  2015-05-01 23:42:01   \n",
       "217  My robot is level 3 and I've earned a total of...  2015-05-01 23:41:51   \n",
       "218  Bitcoin dood? Goldman Sachs gelooft er nog in ...  2015-05-01 23:41:30   \n",
       "219  Obsolete ASIC mining... useful to prevent 51% ...  2015-05-01 23:41:23   \n",
       "\n",
       "        user_name     user_id  followers  \n",
       "215  toshi_kaseda  2941941391       1037  \n",
       "216    CoinfeedIO  2961909107       1336  \n",
       "217    ChrissCoin  3121596999         13  \n",
       "218      CAWAMcom  3152422890        876  \n",
       "219    bonniemck3  2809127089        338  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 5)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
